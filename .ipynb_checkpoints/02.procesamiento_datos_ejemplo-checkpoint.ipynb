{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d8a15e",
   "metadata": {},
   "source": [
    "# Procesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3878fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d190f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"titanic 1.csv\")\n",
    "df2 = pd.read_csv(\"titanic 2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16584aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df1, df2, on = \"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2879ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738336e4",
   "metadata": {},
   "source": [
    "**Es importante saber con cuantos elementos (filas) y atributos (columnas) estámos trabajando, además de conocer sus tipos de datos y su información estadística, y si fuese necesario, cambiar el tipo de dato de las columnas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78187d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .shape nos da el número de filas y columnas\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .describe() nos da un DataFrame con la información estadística de las columnas\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ddb592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .info() nos da el tipo de variables de cada columna y si hay algun valor NaN\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f4bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de NaN's\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ca7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcentaje de NaN's en cada columna\n",
    "\n",
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937c863",
   "metadata": {},
   "source": [
    "## División entre variables numéricas y categóricas\n",
    "\n",
    "En esta parte vamos a separar las columnas númericas y las columnas no númericas.\n",
    "\n",
    "Vamos a tener 2 DataFrames, llamados **`df_num`** y **`df_cat`** respectivamente.\n",
    "\n",
    "El objetivo de esto es trabajar de una forma más cómoda con el DataFrame, conocer cuales columnas no son númericas y aplicarle funciones correspondientes a cada columna dependiendo de su tipo de dato.\n",
    "\n",
    "**Al final esta parte, el DataFrame no númerico va a pasar a tener solo columnas númericas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06387be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_num\n",
    "\n",
    "# ._get_numeric_data() filtra el DataFrame y retorna solo las columnas con valores númericos.\n",
    "\n",
    "# Si tenemos alguna columna con valores númericos pero el tipo de dato no es el correcto la función\n",
    "# ._get_numeric_data() seguramente falle.\n",
    "\n",
    "df_num = df._get_numeric_data().copy()\n",
    "\n",
    "df_num.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8cb927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cat\n",
    "\n",
    "# df_cat sería el DataFrame resultante si quitamos las columnas de df_num\n",
    "\n",
    "df_cat = df.drop(df_num.columns, axis = 1)\n",
    "\n",
    "df_cat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb3deb",
   "metadata": {},
   "source": [
    "## df_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0965fd",
   "metadata": {},
   "source": [
    "### Imputer\n",
    "\n",
    "La imputación de datos es la sustitución de valores no informados (NaN's) en una observación por otros.\n",
    "\n",
    "En general existen 2 técnicas:\n",
    "\n",
    "1. La primera técnica consiste en rellenar estos valores con la **media** (o **mediana**) de los datos de la variable en el caso de que se trate de una **variable numérica**. Para el caso de las **variables categóricas** imputamos los valores perdidos con la **moda** de la variable.\n",
    "\n",
    "\n",
    "2. La segunda técnica, que es más avanzada, consiste en el uso de **modelos predictivos** para estimar los valores perdidos. Un modelo no paramétrico muy popular para estos casos es el **k-nearest neighbors (KNN)**, donde se estima el valor perdido como la media (en el caso de las variables numéricas) de los valores de los **k-vecinos u observaciones mas cercanos**. Analogamente, para las **variables categóricas**, se utiliza las **clase mayoritaria de entre los k mas cercanos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae94bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Primera técnica:\n",
    "\n",
    "# Para la imputación de los datos vamos a \"llenar\" los NaN's por la media de edad\n",
    "\n",
    "df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "\n",
    "# En este ejemplo llena TODOS los NaN's por la misma media.\n",
    "# NOTA: No se ejecutó in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda técnica:\n",
    "\n",
    "# Reemplaza los NaN's de la columna \"Age\" por la media de las edades de los k-vecinos mas cercanos (KNN).\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors = 3)\n",
    "\n",
    "df_num_imp = imputer.fit_transform(df_num)\n",
    "\n",
    "df_num_imp\n",
    "\n",
    "# El resultado de utilizar el KNNImputer es un array.\n",
    "# Esto quiere decir que se pierde el formato de DataFrame, por lo tanto perdemos el nombre de las columnas.\n",
    "\n",
    "# En este ejemplo llena cada NaN's por la media de las edades de los k-vecinos más cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para volver a tener el DataFrame con las columnas volver a definir el objeto.\n",
    "\n",
    "df_num = pd.DataFrame(df_num_imp, columns = df_num.columns)\n",
    "\n",
    "df_num.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef07888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya no hay NaN's en la columna \"Age\"\n",
    "\n",
    "df_num.isnull().sum()/df_num.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f0f5f5",
   "metadata": {},
   "source": [
    "## df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ec213",
   "metadata": {},
   "source": [
    "### Nuevas variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eedea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat[\"Surname\"] = df_cat[\"Name\"].apply(lambda x : x.split(\",\")[0])\n",
    "\n",
    "df_cat[\"Mr./Mrs.\"] = df_cat[\"Name\"].apply(lambda x : x.split(\" \")[1])\n",
    "\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ef322",
   "metadata": {},
   "source": [
    "### Surname\n",
    "\n",
    "Vamos a crear una categoria nueva partiendo del apellido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab5ac3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cat[\"Surname\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5465d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_apellidos = df_cat[\"Surname\"].value_counts().to_dict()\n",
    "\n",
    "dict_apellidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si el apellido se repite 1 vez lo agrega a la categoria Soltero\n",
    "# Si el apellido se repite 2 veces lo agrega a la categoria Pareja\n",
    "# Si el apellido se repite entre 3 y 4 veces lo agrego a la categoria Familia\n",
    "# Si el apellido se repite mas de 4 veces lo agrego a la categoria Familia Grande\n",
    "\n",
    "def func_apellidos(dict_apellidos):\n",
    "    \n",
    "    for apellido, count in dict_apellidos.items():\n",
    "        if count == 1:\n",
    "            dict_apellidos[apellido] = \"Soltero\"\n",
    "        elif count == 2:\n",
    "            dict_apellidos[apellido] = \"Pareja\"\n",
    "        elif count < 5:\n",
    "            dict_apellidos[apellido] = \"Familia\"\n",
    "        else:\n",
    "            dict_apellidos[apellido] = \"Familia Grande\"\n",
    "            \n",
    "    return dict_apellidos\n",
    "            \n",
    "dict_apellidos = func_apellidos(dict_apellidos)\n",
    "\n",
    "dict_apellidos   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat[\"Family\"] = df_cat[\"Surname\"].map(dict_apellidos)\n",
    "\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223145b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos la distribución de la nueva columna\n",
    "\n",
    "sns.countplot(x = df_cat[\"Family\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12be430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La categoria de Soltero es muy grande (existe un desbalance), vamos a unir las otras 3 categorias para poder nivelarlo\n",
    "\n",
    "# Nota: Podemos hacer cualquier cosa que se nos ocurra, esto es una posibilidad de todo lo que podemos hacer.\n",
    "\n",
    "df_cat[\"Family\"] = df_cat[\"Family\"].replace({\"Pareja\" : \"Familia\", \"Familia Grande\" : \"Familia\"})\n",
    "\n",
    "sns.countplot(x = df_cat[\"Family\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df39642",
   "metadata": {},
   "source": [
    "### Mr./Mrs.\n",
    "\n",
    "\n",
    "Vamos a hacer limpieza de esta columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1817c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat[\"Mr./Mrs.\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b26baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a crear otra categoria a partir del Mr. y Mrs.\n",
    "\n",
    "dict_mr = df_cat[\"Mr./Mrs.\"].value_counts().to_dict()\n",
    "dict_mr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577bcbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función que clasifique según el valor de cada fila.\n",
    "\n",
    "def func_mr(dict_mr):\n",
    "    \n",
    "    for mr, count in dict_mr.items():\n",
    "        if mr == \"Mr.\":\n",
    "            dict_mr[mr] = \"Mr.\"\n",
    "            \n",
    "        elif mr == \"Mrs.\":\n",
    "            dict_mr[mr] = \"Mrs.\"\n",
    "            \n",
    "        elif mr == \"Miss.\":\n",
    "            dict_mr[mr] = \"Miss.\"\n",
    "            \n",
    "        else:\n",
    "            dict_mr[mr] = \"Other\"\n",
    "            \n",
    "    return dict_mr\n",
    "            \n",
    "dict_mr = func_mr(dict_mr)\n",
    "\n",
    "dict_mr   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat[\"Title\"] = df_cat[\"Mr./Mrs.\"].map(dict_mr)\n",
    "\n",
    "df_cat.drop(\"Mr./Mrs.\", axis = 1, inplace = True)\n",
    "\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = df_cat[\"Title\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798747a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta vez voy a decidir no unir las categorias, si vemos los datos de la columna \"Sex\"\n",
    "# podemos ver que hay mas hombres que mujeres, por lo que si unimos las 3 categorias menores \n",
    "# vamos a quedar practicamente con la misma informacion que la columna \"Sex\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ede4f6",
   "metadata": {},
   "source": [
    "### Sex, Familia, Title\n",
    "\n",
    "Ya tenemos la información limpia de estas 3 columnas, ahora debemos transformar estas columnas a numéricas.\n",
    "\n",
    "Para esto existen 2 funciones:\n",
    "1. **pd.get_dummies()**: esta función va a generar una columna por cada elemento único en una columna y, dependiendo del valor, va a colocar 1 en la columna correspondiente y 0 en las otras. Esté método resulta de utilidad cuando la categoria no sigue un orden en particular.\n",
    "\n",
    "\n",
    "2. **sklearn.preprocessing.LabelEncoder()**: esta función transforma toda la columna a números enteros, si la columna tiene n elementos únicos, va a cambiar esos elementos por lo números desde el **`0 hasta n - 1`**. Éste método resulta de utilidad si la categoria sigue cierto orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a18d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data = df_cat[\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para unir estas nuevas columnas a df_cat podemos hacer un pd.concat()\n",
    "\n",
    "df_cat = pd.concat([df_cat, pd.get_dummies(data = df_cat[\"Sex\"])], axis = 1)\n",
    "\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ee333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y ahora podemos eliminar la columna \"Sex\"\n",
    "\n",
    "df_cat.drop(\"Sex\", axis = 1, inplace = True)\n",
    "\n",
    "df_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a repetir la operación con las columnas \"Family\" y \"Title\"\n",
    "\n",
    "for col in [\"Family\", \"Title\"]:\n",
    "    \n",
    "    df_cat = pd.concat([df_cat, pd.get_dummies(data = df_cat[col])], axis = 1)\n",
    "\n",
    "    df_cat.drop(col, axis = 1, inplace = True)\n",
    "    \n",
    "df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45be507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora voy a hacer drop de las columnas \"Name\", \"Surname\" y \"Ticket\"\n",
    "# De la columna \"Name\" sacamos \"Surname\" y luego \"Family\", por lo que es información redundate\n",
    "# Y de la columna \"Ticket\" podemos sacar información similar a la que sacamos con la columna \"Surname\"\n",
    "\n",
    "df_cat.drop([\"Name\", \"Surname\", \"Ticket\"], axis = 1, inplace = True)\n",
    "\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8a327",
   "metadata": {},
   "source": [
    "# df_num:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef07bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d43c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La columna Pclass es categorica y numerica, por lo que la vamos a dejar tal cual está\n",
    "# La columna Survived es la columna que queremos predecir\n",
    "# La columna PassengerId es un indice, tiene todos los valores diferentes, por lo tanto, vamos a hacer .drop() de esta columna\n",
    "\n",
    "df_num.drop(\"PassengerId\", axis = 1, inplace = True)\n",
    "\n",
    "df_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f5de95",
   "metadata": {},
   "source": [
    "### Binning\n",
    "Binning es un proceso de transformación de variables numéricas continuas en \"contenedores\" categóricos discretos, para análisis agrupados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc22e4f",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdd319",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_num[\"Fare\"], bins = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb16d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a aplicar Binning a esta columna, bins = 4\n",
    "\n",
    "bins = np.linspace(min(df_num[\"Fare\"]), max(df_num[\"Fare\"]), 5)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f6c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias = [\"Poco\", \"Medio\", \"Alto\", \"Mucho\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3edc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num[\"Fare-Binning\"] = pd.cut(df_num[\"Fare\"], bins, labels = categorias, include_lowest = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85155ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = df_num[\"Fare-Binning\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que el binning se ve afectado por los outliers de esta columna\n",
    "# Vamos a eliminarlos\n",
    "\n",
    "df_num = df_num[df_num[\"Fare\"] < 400]\n",
    "\n",
    "sns.histplot(df_num[\"Fare\"], bins = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1834240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos otra vez Binning\n",
    "\n",
    "bins = np.linspace(min(df_num[\"Fare\"]), max(df_num[\"Fare\"]), 5)\n",
    "\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7821d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias = [\"Poco\", \"Medio\", \"Alto\", \"Mucho\"]\n",
    "\n",
    "df_num[\"Fare-Binning\"] = pd.cut(df_num[\"Fare\"], bins, labels = categorias, include_lowest = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = df_num[\"Fare-Binning\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280670bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existe un desbalance muy grande aún\n",
    "\n",
    "# Vamos a hacer 3 grupos en lugar de 4\n",
    "\n",
    "\n",
    "bins = np.linspace(min(df_num[\"Fare\"]), max(df_num[\"Fare\"]), 4)\n",
    "\n",
    "categorias = [\"Poco\", \"Medio\", \"Alto\"]\n",
    "\n",
    "df_num[\"Fare-Binning\"] = pd.cut(df_num[\"Fare\"], bins, labels = categorias, include_lowest = True)\n",
    "\n",
    "sns.countplot(x = df_num[\"Fare-Binning\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aun existe un desbalance importante\n",
    "\n",
    "# Por ahora dejemos esta columna como está y luego veremos si es de importancia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb8d971",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554644cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_num[\"Age\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ba48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a hacer Binning con bins = 3\n",
    "\n",
    "bins = np.linspace(min(df_num[\"Age\"]), max(df_num[\"Age\"]), 4)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias = [\"Joven\", \"Adulto\", \"Viejo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eba80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num[\"Age-Binning\"] = pd.cut(df_num[\"Age\"], bins, labels = categorias, include_lowest = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3098e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca1df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = df_num[\"Age-Binning\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a dejarlo así, y vamos a convertir esta columna a numerica con LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Inicializamos un objeto LabelEncoder()\n",
    "age_labelEncoding = LabelEncoder()\n",
    "\n",
    "# Lo \"entrenamos\" con los datos de la columna\n",
    "age_labelEncoding.fit(df_num[\"Age-Binning\"].values)\n",
    "\n",
    "# Transformamos la columna\n",
    "age = age_labelEncoding.transform(df_num[\"Age-Binning\"].values)\n",
    "\n",
    "age\n",
    "\n",
    "# El resultado es la columna cambiada a numeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num[\"Age-Binning\"] = age\n",
    "\n",
    "df_num[\"Age-Binning\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a8b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a hacer lo mismo con \"Fare-Binning\"\n",
    "\n",
    "# Inicializamos un objeto LabelEncoder()\n",
    "fare_labelEncoding = LabelEncoder()\n",
    "\n",
    "# Lo \"entrenamos\" con los datos de la columna\n",
    "fare_labelEncoding.fit(df_num[\"Fare-Binning\"].values)\n",
    "\n",
    "# Transformamos la columna\n",
    "fare = fare_labelEncoding.transform(df_num[\"Fare-Binning\"].values)\n",
    "\n",
    "df_num[\"Fare-Binning\"] = fare\n",
    "\n",
    "df_num[\"Fare-Binning\"].value_counts()\n",
    "\n",
    "# El resultado es la columna cambiada a numeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61529049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8cc108",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a unir df_num y df_cat\n",
    "\n",
    "df = pd.concat([df_num, df_cat], axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA: Como eliminamos filas de df_num y no eliminamos filas de df_cat, el DataFrame tendrá NaN's\n",
    "\n",
    "df.isnull().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2358dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos hacer una imputación de los datos, pero par este ejemplo vamos a eliminar esas filas\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "df.isnull().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3888b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a separar la columna \"objetivo\" del resto de columnas\n",
    "df_class = df[\"Survived\"].copy()\n",
    "\n",
    "# Como ya tenemos la columna \"objetivo\" en otra variable vamos a eliminarla del DataFrame original\n",
    "df.drop(\"Survived\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d0bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya tenemos todos los datos en numericos, vamos a hacer Feature Selection\n",
    "# Este primer Feature Selection lo hare utilizando la columna \"Age-Binning\" (excluyendo \"Age\")\n",
    "\n",
    "X = np.asarray(df.drop(\"Age\", axis = 1))\n",
    "y = np.asarray(df_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd293d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators = 250, random_state = 0)\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis = 0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f): %s\" % (f + 1, indices[f], importances[indices[f]], df.columns[f]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color = \"r\", yerr = std[indices], align = \"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5bb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora otro Feature Selection pero esta vez excluyendo \"Age-Binning\"\n",
    "\n",
    "X = np.asarray(df.drop(\"Age-Binning\", axis = 1))\n",
    "y = np.asarray(df_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1962549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators = 250, random_state = 0)\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis = 0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f): %s\" % (f + 1, indices[f], importances[indices[f]], df.columns[f]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color = \"r\", yerr = std[indices], align = \"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
